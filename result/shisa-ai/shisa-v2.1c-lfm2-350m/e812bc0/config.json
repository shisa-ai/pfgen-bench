{"engine": "vllm", "max_tokens": 300, "mode": "chat", "model": "shisa-ai/shisa-v2.1c-lfm2-350m", "num_examples": 20, "quantization": null, "stop": ["Q:"], "temperature": 0.7, "tensor_parallel_size": -1, "top_p": 0.9}
