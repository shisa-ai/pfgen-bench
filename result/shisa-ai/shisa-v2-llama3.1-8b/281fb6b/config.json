{"engine": "vllm", "max_tokens": 300, "mode": "chat", "model": "shisa-ai/shisa-v2-llama3.1-8b", "num_examples": 20, "quantization": null, "stop": ["Q:"], "temperature": 0.7, "tensor_parallel_size": -1, "top_p": 0.9}
